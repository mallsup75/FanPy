{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries if not already present\n",
        "!pip install azure-storage-blob pandas\n",
        "\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import io\n",
        "\n",
        "# Connect to Azure Blob Storage\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=sg092620240215;AccountKey=+PaTF6WCZ0NY63Hni1XIWRJfWsnTI7QJCLVP0f1OXUoVzJyl0AcE4h2Pe1b7ZbgldGkDDFA0j9iK+AStvU4auA==;EndpointSuffix=core.windows.net\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(\"silver\")\n",
        "\n",
        "# Function to find the latest merged_rosters_players_*.csv\n",
        "def get_latest_csv(container_client, prefix=\"merged_rosters_players_\"):\n",
        "    latest_blob = None\n",
        "    latest_time = None\n",
        "    for blob in container_client.list_blobs(name_starts_with=prefix):\n",
        "        print(f\"Processing blob: {blob.name}\")\n",
        "        try:\n",
        "            parts = blob.name.split(\"_\")\n",
        "            if len(parts) < 5:\n",
        "                print(f\"Skipping {blob.name}: Not enough parts\")\n",
        "                continue\n",
        "            timestamp_str = f\"{parts[-2]}_{parts[-1].replace('.csv', '')}\"\n",
        "            timestamp = datetime.strptime(timestamp_str, \"%Y%m%d_%H%M%S\")\n",
        "            if latest_time is None or timestamp > latest_time:\n",
        "                latest_time = timestamp\n",
        "                latest_blob = blob.name\n",
        "        except ValueError as e:\n",
        "            print(f\"Skipping {blob.name}: Invalid timestamp ({e})\")\n",
        "            continue\n",
        "    return latest_blob\n",
        "\n",
        "# Check for latest CSV\n",
        "latest_blob = get_latest_csv(container_client)\n",
        "if not latest_blob:\n",
        "    raise ValueError(\"No merged_rosters_players_*.csv files found\")\n",
        "else:\n",
        "    print(f\"Latest CSV found: {latest_blob}\")\n",
        "\n",
        "# Load the latest CSV\n",
        "print(f\"Loading {latest_blob}\")\n",
        "blob_client = container_client.get_blob_client(latest_blob)\n",
        "blob_data = blob_client.download_blob().readall().decode(\"utf-8\")\n",
        "df = pd.read_csv(io.StringIO(blob_data))\n",
        "\n",
        "# Define position group mapping\n",
        "def assign_position_group(pos):\n",
        "    if pos in ['CF', 'DH', 'LF', 'RF']:\n",
        "        return 'OFD'\n",
        "    elif pos in ['P', 'SP', 'RP']:\n",
        "        return 'P'\n",
        "    #elif pos in ['2B', 'SS']:\n",
        "    #    return 'MI'\n",
        "    #elif pos in ['1B', '3B']:\n",
        "    #    return 'CI'\n",
        "    else:\n",
        "        return 'Other'  # Default for unmatched positions\n",
        "\n",
        "\n",
        "# Add the new position_group column\n",
        "df['position_group'] = df['pos'].apply(assign_position_group)\n",
        "\n",
        "\n",
        "# Save the updated DataFrame back to silver\n",
        "output_blob_name = f\"merged_rosters_players_with_groups_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "output_blob_client = container_client.get_blob_client(output_blob_name)\n",
        "output_csv = df.to_csv(index=False)\n",
        "output_blob_client.upload_blob(output_csv, overwrite=True)\n",
        "print(f\"Uploaded updated CSV to silver as {output_blob_name}\")\n",
        "\n",
        "# Display the updated DataFrame (using pandas print instead of Databricks display)\n",
        "print(\"Updated DataFrame:\")\n",
        "print(df.head())  # Show first 5 rows"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1741449409375
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython",
      "codemirror_mode": "ipython",
      "nbconvert_exporter": "python"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
